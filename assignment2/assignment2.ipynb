{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ct_support_code import *\n",
    "\n",
    "\n",
    "data = np.load('ct_data.npz')\n",
    "X_train = data['X_train']; X_val = data['X_val']; X_test = data['X_test']\n",
    "y_train = data['y_train']; y_val = data['y_val']; y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "y_train mean:  -9.13868774539957e-15\ny_val mean with standard error: -0.2160085093241599 ± 0.012903383410668334\ny_train 5785 samples mean with standard error: -0.44247687859693674 ± 0.01192627246273395\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "\"\\nWe see that y_train mean with the error bar for\\nonly 5785 samples is far away from zero (y_train mean).\\nAs number of samples in y_train is much larger than number of samples in y_val,\\nwe can't make our predictions of y_val mean just based on y_train mean \\nwith the standard error bar...better explanation..\\n\""
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "# 1 a)\n",
    "y_train_mean = y_train.mean()\n",
    "print('y_train mean: ', y_train_mean)\n",
    "\n",
    "y_val_mean = y_val.mean()\n",
    "y_val_error = y_val.std()/np.sqrt(len(y_val))\n",
    "\n",
    "y_train_error = y_train[:5785].std()/np.sqrt(5785)\n",
    "print(f'y_val mean with standard error: {y_val_mean} ± {y_val_error}')\n",
    "print(f'y_train 5785 samples mean with standard error: {y_train[:5785].mean()} ± {y_train_error}')\n",
    "\n",
    "\"\"\"\n",
    "We see that y_train mean with the error bar for\n",
    "only 5785 samples is far away from zero (y_train mean).\n",
    "As number of samples in y_train is much larger than number of samples in y_val,\n",
    "we can't make our predictions of y_val mean just based on y_train mean \n",
    "with the standard error bar...better explanation..\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Indexes of constant columns: [59, 69, 179, 189, 351]\n",
      "Original indexes of duplicate columns [78, 79, 69, 179, 199, 188, 189, 351, 287, 359]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 1 b)\n",
    "\n",
    "remove_indexes = [i for i,col in enumerate(X_train.T) if np.all(col==col[0])]\n",
    "print('Indexes of constant columns:', remove_indexes)\n",
    "remove_indexes_2 = []\n",
    "for i, col1 in enumerate(X_train.T):\n",
    "    for j, col2 in enumerate(X_train.T[i+1:,:]):\n",
    "        if np.all(col1==col2):\n",
    "            remove_indexes_2.append(i+j+1)\n",
    "            break       \n",
    "print('Original indexes of duplicate columns', remove_indexes_2)\n",
    "remove_indexes = remove_indexes + remove_indexes_2\n",
    "X_train = np.delete(X_train, remove_indexes, axis=1)\n",
    "X_val = np.delete(X_val, remove_indexes, axis=1)\n",
    "X_test = np.delete(X_test, remove_indexes, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training RMSE (fit_linreg):  0.3567669814948786\nTraining RMSE (fit_linreg_gradopt):  0.35675561493545876\nValidation RMSE (fit_linreg):  0.42292954946321326\nValidation RMSE (fit_linreg_gradopt):  0.42305590683687927\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "'\\nValues close to each other, but not exactly the same\\nfit_linreg_gradopt is better on training\\nAdd explanation..numerical reasons..different method?\\nval rmse smaller..?\\n'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "# 2 \n",
    "def fit_linreg(X, yy, alpha):\n",
    "    K = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "    X = np.column_stack((X,np.ones(N)))\n",
    "    X = np.row_stack((X,np.sqrt(alpha)*np.eye(K+1)))\n",
    "    y = np.concatenate((yy, np.zeros(K+1)))\n",
    "    w = np.linalg.lstsq(X,y,rcond=None)[0]\n",
    "    return w[:-1], w[-1]\n",
    "\n",
    "def rmse(ww, bb, XX, yy):\n",
    "    return np.sqrt(np.mean(((XX @ ww + bb) - yy)**2))\n",
    "\n",
    "alpha = 30\n",
    "train_w1, train_b1 = fit_linreg(X_train, y_train, alpha)\n",
    "train_w2, train_b2 = fit_linreg_gradopt(X_train, y_train, alpha)\n",
    "print('Training RMSE (fit_linreg): ', rmse(train_w1, train_b1, X_train, y_train))\n",
    "print('Training RMSE (fit_linreg_gradopt): ', rmse(train_w2, train_b2, X_train, y_train))\n",
    "print('Validation RMSE (fit_linreg): ', rmse(train_w1, train_b1, X_val, y_val))\n",
    "print('Validation RMSE (fit_linreg_gradopt): ', rmse(train_w2, train_b2, X_val, y_val))\n",
    "\n",
    "\"\"\"\n",
    "Values close to each other, but not exactly the same\n",
    "fit_linreg_gradopt is better on training\n",
    "Add explanation..numerical reasons..different method?\n",
    "val rmse smaller..?\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training RMSE logreg transformation (fit_linreg_gradopt):  0.15441194427307056\nValidation RMSE logreg transformation (fit_linreg_gradopt):  0.2542485765839827\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "' Lower RMSE than normal linear regression '"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "# 3\n",
    "K = 20 # number of thresholded classification problems to fit\n",
    "mx = np.max(y_train); mn = np.min(y_train); hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "\n",
    "\n",
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb\n",
    "\n",
    "def logreg_forward(X, ww, bb):\n",
    "    aa = (X @ ww) + bb\n",
    "    return 1 / (1 + np.exp(-aa))\n",
    "\n",
    "N = X_train.shape[0]\n",
    "D = X_train.shape[1]\n",
    "WW = np.empty((D, K))\n",
    "BB = np.empty(K)\n",
    "LL = np.empty((N, K))\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "    LL[:, kk] = labels\n",
    "    WW[:,kk], BB[kk] = fit_logreg_gradopt(X_train, labels, alpha)\n",
    "\n",
    "\n",
    "X_train_logreg = logreg_forward(X_train, WW, BB) \n",
    "X_val_logreg = logreg_forward(X_val, WW, BB) \n",
    "\n",
    "train_w_lr, train_b_lr = fit_linreg_gradopt(X_train_logreg, y_train, alpha)\n",
    "print('Training RMSE logreg transformation (fit_linreg_gradopt): ', \n",
    "      rmse(train_w_lr, train_b_lr, X_train_logreg, y_train))\n",
    "print('Validation RMSE logreg transformation (fit_linreg_gradopt): ', \n",
    "      rmse(train_w_lr, train_b_lr, X_val_logreg, y_val))\n",
    "\"\"\" Lower RMSE than normal linear regression \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "NN train RMSE with random initialization parameters:  0.13942065852907823\nNN val RMSE with random initialization parameters:  0.2684920995102662\nNN train RMSE with q3 initialization parameters:  0.13858869596445625\nNN val RMSE with q3 initialization parameters:  0.2706637451683212\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 4\n",
    "def fit_nn_gradopt(X, yy, alpha, K=20, init=None):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    if init==None:\n",
    "        init = (np.random.randn(K), np.array(0), np.random.randn(K, D), np.random.randn(K))\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk\n",
    "\n",
    "def nn_rmse(params, XX, yy):\n",
    "    ww, bb, V, bk = params\n",
    "    \n",
    "    A = np.dot(XX, V.T) + bk[None,:] # N,K\n",
    "    P = 1 / (1 + np.exp(-A)) # N,K\n",
    "    F = np.dot(P, ww) + bb # N,\n",
    "    E =  np.sqrt(np.mean((F - yy)**2))\n",
    "    return E\n",
    "\n",
    "nn_rand_params = fit_nn_gradopt(X_train, y_train, 30)\n",
    "q3_params = (train_w_lr, train_b_lr, WW.T, BB)\n",
    "nn_q3_params = fit_nn_gradopt(X_train, y_train, 30, init=q3_params)\n",
    "#print(\"NN cost with random initialization parameters: \", nn_cost(nn_rand_params, X_train, yy=y_train, alpha=30)[0])\n",
    "#print(\"NN cost with q3 initialization parameters: \", nn_cost(nn_q3_params, X_train, yy=y_train, alpha=30)[0])\n",
    "print(\"NN train RMSE with random initialization parameters: \", nn_rmse(nn_rand_params, X_train, y_train))\n",
    "print(\"NN val RMSE with random initialization parameters: \", nn_rmse(nn_rand_params, X_val, y_val))\n",
    "print(\"NN train RMSE with q3 initialization parameters: \", nn_rmse(nn_q3_params, X_train, y_train))\n",
    "print(\"NN val RMSE with q3 initialization parameters: \", nn_rmse(nn_q3_params, X_val, y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2706637451683212"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 25
    }
   ],
   "source": [
    "# 5\n",
    "def nn_rmse(params, XX, yy):\n",
    "    ww, bb, V, bk = params\n",
    "\n",
    "    A = np.dot(XX, V.T) + bk[None, :]  # N,K\n",
    "    P = 1 / (1 + np.exp(-A))  # N,K\n",
    "    F = np.dot(P, ww) + bb  # N,\n",
    "    E = np.sqrt(np.mean((F - yy) ** 2))\n",
    "    return E\n",
    "\n",
    "nn_rmse(nn_q3_params, X_val, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_b_lr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "WW.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}